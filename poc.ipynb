{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "import bs4\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", device=0) #GPU\n",
    "candidate_labels = [\"positive\", \"negative\"]\n",
    "\n",
    "# 將RAW DATA 有意義的 內文 撈出來\n",
    "def get_content(soup):\n",
    "    ## 查找所有html 元素 抓出內容\n",
    "    main_container = soup.find(id='main-container')\n",
    "    # 把所有文字都抓出來\n",
    "    all_text = main_container.text\n",
    "    # 把整個內容切割透過 \"-- \" 切割成2個陣列\n",
    "    pre_text = all_text.split('--')[0]\n",
    "    # 把每段文字 根據 '\\n' 切開\n",
    "    texts = pre_text.split('\\n')\n",
    "    # 如果你爬多篇你會發現 \n",
    "    contents = texts[2:]\n",
    "    # 內容\n",
    "    content = ''.join(contents)\n",
    "    return content\n",
    "\n",
    "# 根據給定的URL計算出TOTAL有幾頁PAGE\n",
    "def get_total_page_number(URL):\n",
    "    response = requests.get(URL, headers = {'cookie': 'over18=1;'})\n",
    "    soup = bs4.BeautifulSoup(response.text,\"html.parser\")\n",
    "    number = int(str(soup.select('#action-bar-container > div > div.btn-group.btn-group-paging > a:nth-child(2)')[0]).split('index')[1].split('.html')[0])\n",
    "    return number\n",
    "\n",
    "# 根據URL取得這個PAGE的資料dataframe格式\n",
    "def get_this_index_data(URL):\n",
    "    # 設定Header與Cookie\n",
    "    my_headers = {'cookie': 'over18=1;'}\n",
    "    # 發送get 請求 到 ptt 八卦版\n",
    "    response = requests.get(URL, headers = my_headers)\n",
    "\n",
    "    #  把網頁程式碼(HTML) 丟入 bs4模組分析\n",
    "    soup = bs4.BeautifulSoup(response.text,\"html.parser\")\n",
    "\n",
    "    ## PTT 上方4個欄位\n",
    "    result = soup.find_all('div','title')\n",
    "    urls = []\n",
    "    titles = []\n",
    "    contents = []\n",
    "    for i in result:\n",
    "        try:\n",
    "            post_url = 'https://www.ptt.cc'+str(i).split('href=\"')[1].split('\">')[0]\n",
    "            urls.append(post_url)\n",
    "            titles.append(str(i).split(\"]\")[1].split(\"<\")[0])\n",
    "            response = requests.get(post_url, headers = my_headers)\n",
    "            soup = bs4.BeautifulSoup(response.text,\"html.parser\")\n",
    "            contents.append(get_content(soup))\n",
    "        except:\n",
    "            pass #(本文已被刪除)\n",
    "    df = pd.DataFrame()\n",
    "    df['title'] = titles\n",
    "    df['url'] = urls\n",
    "    df['content'] = contents\n",
    "    return df\n",
    "\n",
    "# 根據URL和指定頁數取得串接多個PAGE後的dataframe格式資料\n",
    "def get_some_page_ptt_data(URL,last_n_page):\n",
    "    total_page_number = get_total_page_number(URL)\n",
    "    URLS = [f\"https://www.ptt.cc/bbs/HatePolitics/index{i}.html\" for i in range(total_page_number,total_page_number-last_n_page,-1)]\n",
    "    df = get_this_index_data(URL) #最新的PAGE\n",
    "    for u in tqdm(URLS): #最近N個PAGE\n",
    "        d = get_this_index_data(u)\n",
    "        df = pd.concat([df,d]) #串起來\n",
    "    return df\n",
    "\n",
    "# 根據URL和指定數量PAGE和特定角色計算聲量分數\n",
    "def get_score_by_person(URL,last_n_page,person_name,save=False):\n",
    "    df = get_some_page_ptt_data(URL,last_n_page)\n",
    "    if save == True:\n",
    "        df.to_excel('ptt_post.xlsx')\n",
    "    df['all_text'] = df['title']+df['content']\n",
    "    idx_lst = []\n",
    "    for idx,text in enumerate(df['all_text']):\n",
    "        if person_name in text:\n",
    "            idx_lst.append(idx)\n",
    "    key_df = df.iloc[idx_lst,:]\n",
    "    key_df = key_df.reset_index(drop=True)\n",
    "    print('資料筆數:',len(key_df))\n",
    "    key_df['情緒'] = 0\n",
    "    for idx,text in tqdm(enumerate(key_df['all_text'].values.tolist())):\n",
    "        key_df.loc[idx,'情緒'] = classifier(text, candidate_labels)['labels'][0]\n",
    "    score = (key_df['情緒']=='positive').sum()/(key_df['情緒']=='negative').sum()\n",
    "    return score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 蔡英文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_5060\\3516813039.py:68: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for u in tqdm(URLS): #最近N個PAGE\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99f3bf67834409bb3d0e7892f53285f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "資料筆數: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_5060\\3516813039.py:87: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for idx,text in tqdm(enumerate(key_df['all_text'].values.tolist())):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532313b2a12142c28f5360e4df36c717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = \"https://www.ptt.cc/bbs/HatePolitics/index.html\"\n",
    "last_n_page = 30\n",
    "get_score_by_person(URL,last_n_page,person_name='蔡英文')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 林智堅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_5060\\3516813039.py:68: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for u in tqdm(URLS): #最近N個PAGE\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cffc5df53e3a44d699e3af13f3a6e911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "資料筆數: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_5060\\3516813039.py:87: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for idx,text in tqdm(enumerate(key_df['all_text'].values.tolist())):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104e6aeff9b94c5e9ea7080f4c7305d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46808510638297873"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score_by_person(URL,last_n_page,person_name='林智堅')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 陳時中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_6500\\684795557.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for idx,text in tqdm(enumerate(key_df['all_text'].values.tolist())):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04363e822e0a48bca4c98eef25c9f582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score_by_person(URL,last_n_page,person_name='陳時中')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57bc2b6ce032b5f0e93daa91901b7ea38a856826ef43aa9e95b6d3999f5310df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
