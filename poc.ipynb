{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "import bs4\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "classifier = pipeline(\"zero-shot-classification\", device=0) #GPU\n",
    "candidate_labels = [\"positive\", \"negative\"]\n",
    "\n",
    "# 將RAW DATA 有意義的 內文 撈出來\n",
    "def get_content(soup):\n",
    "    ## 查找所有html 元素 抓出內容\n",
    "    main_container = soup.find(id='main-container')\n",
    "    # 把所有文字都抓出來\n",
    "    all_text = main_container.text\n",
    "    # 把整個內容切割透過 \"-- \" 切割成2個陣列\n",
    "    pre_text = all_text.split('--')[0]\n",
    "    # 把每段文字 根據 '\\n' 切開\n",
    "    texts = pre_text.split('\\n')\n",
    "    # 如果你爬多篇你會發現 \n",
    "    contents = texts[2:]\n",
    "    # 內容\n",
    "    content = ''.join(contents)\n",
    "    return content\n",
    "\n",
    "# 根據給定的URL計算出TOTAL有幾頁PAGE\n",
    "def get_total_page_number(URL):\n",
    "    response = requests.get(URL, headers = {'cookie': 'over18=1;'})\n",
    "    soup = bs4.BeautifulSoup(response.text,\"html.parser\")\n",
    "    number = int(str(soup.select('#action-bar-container > div > div.btn-group.btn-group-paging > a:nth-child(2)')[0]).split('index')[1].split('.html')[0])\n",
    "    return number\n",
    "\n",
    "# 根據URL取得這個PAGE的資料dataframe格式\n",
    "def get_this_index_data(URL):\n",
    "    # 設定Header與Cookie\n",
    "    my_headers = {'cookie': 'over18=1;'}\n",
    "    # 發送get 請求 到 ptt 八卦版\n",
    "    response = requests.get(URL, headers = my_headers)\n",
    "\n",
    "    #  把網頁程式碼(HTML) 丟入 bs4模組分析\n",
    "    soup = bs4.BeautifulSoup(response.text,\"html.parser\")\n",
    "\n",
    "    ## PTT 上方4個欄位\n",
    "    result = soup.find_all('div','title')\n",
    "    urls = []\n",
    "    titles = []\n",
    "    contents = []\n",
    "    for i in result:\n",
    "        try:\n",
    "            post_url = 'https://www.ptt.cc'+str(i).split('href=\"')[1].split('\">')[0]\n",
    "            urls.append(post_url)\n",
    "            titles.append(str(i).split(\"]\")[1].split(\"<\")[0])\n",
    "            response = requests.get(post_url, headers = my_headers)\n",
    "            soup = bs4.BeautifulSoup(response.text,\"html.parser\")\n",
    "            contents.append(get_content(soup))\n",
    "        except:\n",
    "            pass #(本文已被刪除)\n",
    "    df = pd.DataFrame()\n",
    "    df['title'] = titles\n",
    "    df['url'] = urls\n",
    "    df['content'] = contents\n",
    "    return df\n",
    "\n",
    "# 根據URL和指定頁數取得串接多個PAGE後的dataframe格式資料\n",
    "def get_some_page_ptt_data(URL,last_n_page):\n",
    "    total_page_number = get_total_page_number(URL)\n",
    "    URLS = [f\"https://www.ptt.cc/bbs/HatePolitics/index{i}.html\" for i in range(total_page_number,total_page_number-last_n_page,-1)]\n",
    "    df = get_this_index_data(URL) #最新的PAGE\n",
    "    for u in tqdm(URLS): #最近N個PAGE\n",
    "        d = get_this_index_data(u)\n",
    "        df = pd.concat([df,d]) #串起來\n",
    "    return df\n",
    "\n",
    "# 根據URL和指定數量PAGE和特定角色計算聲量分數\n",
    "def get_score_by_person(URL,last_n_page,person_name,save=False):\n",
    "    df = get_some_page_ptt_data(URL,last_n_page)\n",
    "    if save == True:\n",
    "        df.to_excel('ptt_post.xlsx')\n",
    "    df['all_text'] = df['title']+df['content']\n",
    "    idx_lst = []\n",
    "    for idx,text in enumerate(df['all_text']):\n",
    "        if person_name in text:\n",
    "            idx_lst.append(idx)\n",
    "    key_df = df.iloc[idx_lst,:]\n",
    "    key_df = key_df.reset_index(drop=True)\n",
    "    print('資料筆數:',len(key_df))\n",
    "    key_df['情緒'] = 0\n",
    "    for idx,text in tqdm(enumerate(key_df['all_text'].values.tolist())):\n",
    "        key_df.loc[idx,'情緒'] = classifier(text, candidate_labels)['labels'][0]\n",
    "    score = (key_df['情緒']=='positive').sum()/(key_df['情緒']=='negative').sum()\n",
    "    return score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 參數設置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.ptt.cc/bbs/HatePolitics/index.html\"\n",
    "last_n_page = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 蔡英文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19faac97f994101ab82c181f04efe72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "資料筆數: 135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a5083c0f8c47fd85c3fa4c75f919c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8493150684931506"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "v1 = get_score_by_person(URL,last_n_page,person_name='蔡英文')\n",
    "v1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 蘇貞昌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddfd40124d86499292d11446c8273e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "資料筆數: 93\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e0adb4bbe749f2a2c6e391cb3d3dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8979591836734694"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "v2 = get_score_by_person(URL,last_n_page,person_name='蘇貞昌')\n",
    "v2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 林智堅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5020ffc3a264460a99d1c3a43cb3d108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "資料筆數: 229\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce54d0ede42e4f2db1188d457c216342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5266666666666666"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v3 = get_score_by_person(URL,last_n_page,person_name='林智堅')\n",
    "v3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 陳時中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33766a3035f418ba88623a2192d971e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "資料筆數: 34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793a84102f044d2199313b9cdc217e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.3076923076923077"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v4 = get_score_by_person(URL,last_n_page,person_name='陳時中')\n",
    "v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57bc2b6ce032b5f0e93daa91901b7ea38a856826ef43aa9e95b6d3999f5310df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
